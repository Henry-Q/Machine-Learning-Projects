{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 3 - LOGISTIC REGRESSION\n",
    "\n",
    "This lab is comprised of two main sections:\n",
    "\n",
    "- 1. Logistic Regression with only numerical variables\n",
    "\n",
    "- 2. Logistic Regression with numerical + categorical variables\n",
    "\n",
    "In this lab we will build up knowledge of `statsmodels`. Additionally, we will introduce another package, `scikit-learn` or `sklearn`, which is wildly used in machine learning and predictive analytics. The documentation for `sklearn` can be found at https://scikit-learn.org/stable/.\n",
    "\n",
    "These are two of the most complete and well-documented libraries for statistical modeling in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we summon `numpy` and `pandas` for dataset representation and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOGISTIC REGRESSION (ONLY NUMERICAL VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9516 entries, 0 to 9515\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   not.fully.paid  9516 non-null   int64  \n",
      " 1   installment     9516 non-null   float64\n",
      " 2   log.annual.inc  9516 non-null   float64\n",
      " 3   fico            9516 non-null   int64  \n",
      " 4   revol.bal       9516 non-null   float64\n",
      " 5   inq.last.6mths  9516 non-null   int64  \n",
      " 6   pub.rec         9516 non-null   int64  \n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 520.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not.fully.paid</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>fico</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>pub.rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>829.10</td>\n",
       "      <td>4.929419</td>\n",
       "      <td>737</td>\n",
       "      <td>28.854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>228.22</td>\n",
       "      <td>4.812913</td>\n",
       "      <td>707</td>\n",
       "      <td>33.623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>366.86</td>\n",
       "      <td>4.505150</td>\n",
       "      <td>682</td>\n",
       "      <td>3.511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>162.34</td>\n",
       "      <td>4.929419</td>\n",
       "      <td>712</td>\n",
       "      <td>33.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>102.92</td>\n",
       "      <td>4.907411</td>\n",
       "      <td>667</td>\n",
       "      <td>4.740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not.fully.paid  installment  ...  inq.last.6mths  pub.rec\n",
       "0               0       829.10  ...               0        0\n",
       "1               0       228.22  ...               0        0\n",
       "2               0       366.86  ...               1        0\n",
       "3               0       162.34  ...               1        0\n",
       "4               0       102.92  ...               0        0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = pd.read_csv(\"loans.csv\")\n",
    "loans.info()\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data cleaning and transformation\n",
    "\n",
    "In Python, a convention is to name variables with underscores. This is slightly different from R. \n",
    "\n",
    "Let us practice how to rename columns in `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['not_fully_paid', 'installment', 'log_annual_inc', 'fico', 'revol_bal',\n",
      "       'inq_last_6mths', 'pub_rec'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_column_names = {'not.fully.paid':'not_fully_paid', 'log.annual.inc':'log_annual_inc',\n",
    "                   'revol.bal':'revol_bal', 'inq.last.6mths':'inq_last_6mths', 'pub.rec':'pub_rec'}\n",
    "loans.rename(columns = new_column_names, inplace = True)\n",
    "\n",
    "print(loans.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `df.describe()`, you can have a quick overview of the data set. Here, observe that the first four variables ('installment', 'log_annual_inc', 'fico', and 'revol_bal') takes continuous numeric values and the last two variables ('inq_last_6mths', 'pub_rec') takes ingeter numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_fully_paid</th>\n",
       "      <th>installment</th>\n",
       "      <th>log_annual_inc</th>\n",
       "      <th>fico</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>pub_rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "      <td>9516.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.159836</td>\n",
       "      <td>320.131185</td>\n",
       "      <td>4.748642</td>\n",
       "      <td>710.841950</td>\n",
       "      <td>16.988484</td>\n",
       "      <td>1.572930</td>\n",
       "      <td>0.062211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.366473</td>\n",
       "      <td>207.069870</td>\n",
       "      <td>0.265002</td>\n",
       "      <td>37.956246</td>\n",
       "      <td>33.721379</td>\n",
       "      <td>2.200329</td>\n",
       "      <td>0.262406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.670000</td>\n",
       "      <td>3.277838</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.020000</td>\n",
       "      <td>4.588821</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>3.272750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>269.545000</td>\n",
       "      <td>4.748188</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>8.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>435.405000</td>\n",
       "      <td>4.903323</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>18.354250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>940.140000</td>\n",
       "      <td>6.309584</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>1207.359000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       not_fully_paid  installment  ...  inq_last_6mths      pub_rec\n",
       "count     9516.000000  9516.000000  ...     9516.000000  9516.000000\n",
       "mean         0.159836   320.131185  ...        1.572930     0.062211\n",
       "std          0.366473   207.069870  ...        2.200329     0.262406\n",
       "min          0.000000    15.670000  ...        0.000000     0.000000\n",
       "25%          0.000000   164.020000  ...        0.000000     0.000000\n",
       "50%          0.000000   269.545000  ...        1.000000     0.000000\n",
       "75%          0.000000   435.405000  ...        2.000000     0.000000\n",
       "max          1.000000   940.140000  ...       33.000000     5.000000\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous labs we saw how to split the dataset according to conditions predicated on variable's values. We now wish to split the dataset using **randomized** methods.\n",
    "\n",
    "In order to perform the splitting, we import a package from `sklearn`. We also set a fixed random state in order to exactly replicate the results at each execution of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6661, 7), (2855, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loans_train, loans_test = train_test_split(loans, test_size=0.3, random_state=88)\n",
    "\n",
    "loans_train.shape, loans_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5585\n",
      "1    1076\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many loans have defaulted in the training set?\n",
    "\n",
    "default_false = np.sum(loans_train['not_fully_paid'] == 0)  # not default \n",
    "default_true = np.sum(loans_train['not_fully_paid'] == 1)   # default\n",
    "\n",
    "print(pd.Series({'0': default_false, '1': default_true}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A baseline model can be a so-called \"dummy\" model, where the classifier predicts every new observation as the majority class. In our case, for a datapoint with any given features, the baseline model will always predict 'no default'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384626932892959"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of baseline model based on training data:\n",
    "\n",
    "ACC = default_false/(default_false + default_true)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we want to create models that performs better than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: compute accuracy of baseline on testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8441330998248686"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # EXERCISE1: Compute accuracy of baseline on testing:\n",
    "\n",
    "default_false_test = np.sum(loans_test['not_fully_paid'] == 0)\n",
    "default_true_test = np.sum(loans_test['not_fully_paid'] == 1)\n",
    "ACC_test = default_false_test/(default_false_test + default_true_test)\n",
    "\n",
    "ACC_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise2: What are the TPR and FPR rates of the baseline model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXERCISE2: What are the TPR and FPR rates of the baseline model? \n",
    "\n",
    "# # True positive: the proportion of actual positives that are correctly identified as positive\n",
    "# # False positive: the proportion of actual negatives that are incorrectly identified as positive\n",
    "\n",
    "# TPR = ???                         # TPR = TP/P = TP/(TP+FN)\n",
    "# FPR = ???                         # FPR = FP/N = FP/(FP+TN)\n",
    "# print(TPR,FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise3: What are the TNR and FNR rates of the baseline model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXERCISE3: What are the TNR and FNR rates of the baseline model? \n",
    "\n",
    "# # True negative: the proportion of actual negatives that are correctly identified as negative\n",
    "# # False negative: the proportion of actual positives that are incorrectly identified as negative\n",
    "\n",
    "# TNR = ???                        # TNR = TN/N = TN/(TN+FP)\n",
    "# FNR = ???                        # FNR = FN/P = FN/(TP+FN)\n",
    "# print(TNR,FNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Model Fitting (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the statsmodels package to fit the training set to a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Create a Model from a formula and dataframe.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "formula : str or generic Formula object\n",
       "    The formula specifying the model.\n",
       "data : array_like\n",
       "    The data for the model. See Notes.\n",
       "subset : array_like\n",
       "    An array-like object of booleans, integers, or index values that\n",
       "    indicate the subset of df to use in the model. Assumes df is a\n",
       "    `pandas.DataFrame`.\n",
       "drop_cols : array_like\n",
       "    Columns to drop from the design matrix.  Cannot be used to\n",
       "    drop terms involving categoricals.\n",
       "*args\n",
       "    Additional positional argument that are passed to the model.\n",
       "**kwargs\n",
       "    These are passed to the model with one exception. The\n",
       "    ``eval_env`` keyword is passed to patsy. It can be either a\n",
       "    :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
       "    indicating the depth of the namespace to use. For example, the\n",
       "    default ``eval_env=0`` uses the calling namespace. If you wish\n",
       "    to use a \"clean\" environment set ``eval_env=-1``.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "model\n",
       "    The model instance.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "data must define __getitem__ with the keys in the formula terms\n",
       "args and kwargs are passed on to the model instantiation. E.g.,\n",
       "a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
       "\u001b[1;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "?smf.logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422149\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         not_fully_paid   No. Observations:                 6661\n",
      "Model:                          Logit   Df Residuals:                     6654\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Fri, 15 Sep 2023   Pseudo R-squ.:                 0.04537\n",
      "Time:                        14:54:06   Log-Likelihood:                -2811.9\n",
      "converged:                       True   LL-Null:                       -2945.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.373e-55\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          8.5765      0.967      8.866      0.000       6.681      10.472\n",
      "installment        0.0010      0.000      5.218      0.000       0.001       0.001\n",
      "log_annual_inc    -0.8537      0.156     -5.457      0.000      -1.160      -0.547\n",
      "fico              -0.0096      0.001     -9.406      0.000      -0.012      -0.008\n",
      "revol_bal          0.0036      0.001      3.435      0.001       0.002       0.006\n",
      "inq_last_6mths     0.1171      0.014      8.454      0.000       0.090       0.144\n",
      "pub_rec            0.2245      0.112      2.004      0.045       0.005       0.444\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model\n",
    "\n",
    "logreg = smf.logit(formula = 'not_fully_paid ~ installment + log_annual_inc + fico + revol_bal + inq_last_6mths + pub_rec',\n",
    "                   data = loans_train).fit()\n",
    "\n",
    "print(logreg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.209408\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of prediction for a new observation\n",
    "\n",
    "new_obs = pd.DataFrame(data = {'installment' : [366], 'log_annual_inc' : [4.51], 'fico' : [682],\n",
    "                               'revol_bal' : [7.53], 'inq_last_6mths' : [1], 'pub_rec' : [0]})\n",
    "\n",
    "logreg.predict(new_obs)  # probability of default (not paying the loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3007    0\n",
       "4497    0\n",
       "8575    0\n",
       "5035    0\n",
       "9037    0\n",
       "       ..\n",
       "7025    0\n",
       "5379    0\n",
       "3972    0\n",
       "2827    0\n",
       "7784    0\n",
       "Length: 2855, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = loans_test['not_fully_paid']\n",
    "\n",
    "y_prob = logreg.predict(loans_test)\n",
    "y_pred = pd.Series([1 if x > 0.5 else 0 for x in y_prob], index=y_prob.index)\n",
    "\n",
    "# y_pred is the vector of probabilities as given by your model on the test set. \n",
    "# Values between 0 and 1.\n",
    "\n",
    "# Remember, P(Yi = 1) = 1/(1 + e^(-(b0 + b1*x1 + b2*x2 +...)) )\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Model Evaluation - Confusion Matrix\n",
    "\n",
    "In order to evaluate the performance of our classification model, we can make use of confusion matrix to compute a variety of useful metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Compute confusion matrix to evaluate the accuracy of a classification.\n",
       "\n",
       "By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
       "is equal to the number of observations known to be in group :math:`i` and\n",
       "predicted to be in group :math:`j`.\n",
       "\n",
       "Thus in binary classification, the count of true negatives is\n",
       ":math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
       ":math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
       "\n",
       "Read more in the :ref:`User Guide <confusion_matrix>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array-like of shape (n_samples,)\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : array-like of shape (n_samples,)\n",
       "    Estimated targets as returned by a classifier.\n",
       "\n",
       "labels : array-like of shape (n_classes), default=None\n",
       "    List of labels to index the matrix. This may be used to reorder\n",
       "    or select a subset of labels.\n",
       "    If ``None`` is given, those that appear at least once\n",
       "    in ``y_true`` or ``y_pred`` are used in sorted order.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "normalize : {'true', 'pred', 'all'}, default=None\n",
       "    Normalizes confusion matrix over the true (rows), predicted (columns)\n",
       "    conditions or all the population. If None, confusion matrix will not be\n",
       "    normalized.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "C : ndarray of shape (n_classes, n_classes)\n",
       "    Confusion matrix whose i-th row and j-th\n",
       "    column entry indicates the number of\n",
       "    samples with true label being i-th class\n",
       "    and predicted label being j-th class.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
       "    given an estimator, the data, and the label.\n",
       "ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
       "    given the true and predicted labels.\n",
       "ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `Wikipedia entry for the Confusion matrix\n",
       "       <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
       "       (Wikipedia and other references may use a different\n",
       "       convention for axes).\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import confusion_matrix\n",
       ">>> y_true = [2, 0, 2, 2, 0, 1]\n",
       ">>> y_pred = [0, 0, 2, 2, 0, 2]\n",
       ">>> confusion_matrix(y_true, y_pred)\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
       ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
       ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       "In the binary case, we can extract true positives, etc as follows:\n",
       "\n",
       ">>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
       ">>> (tn, fp, fn, tp)\n",
       "(0, 2, 1, 1)\n",
       "\u001b[1;31mFile:\u001b[0m      ~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "?confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remind you of what each element of the confusion matrix represents:\n",
    "\n",
    "TN FP\n",
    "\n",
    "FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[2404    6]\n",
      " [ 435   10]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix : \\n\", cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2410,    0],\n",
       "       [ 445,    0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the confusion matrix of the baseline model\n",
    "confusion_matrix(loans_test['not_fully_paid'],[0]*loans_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2404    6  435   10]\n"
     ]
    }
   ],
   "source": [
    "print(cm.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455341506129597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "Acc_logit = (cm.ravel()[0]+cm.ravel()[3])/sum(cm.ravel())  # T/total = (TP+TN)/total\n",
    "Acc_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful about the definitions of FPR, TPR, recall, precision, sensitivity, specificity etc:\n",
    "https://en.wikipedia.org/wiki/Sensitivity_and_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Calculate TPR and FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXERCISE: What is the True Positive Rate ?\n",
    "# TPR_logit = ???               #TP/P=TP/(TP+ FN)\n",
    "# print('TPR is: %.4f' % TPR_logit)\n",
    "\n",
    "\n",
    "# # EXERCISE: What is the False Positive rate ?\n",
    "# FPR_logit = ???                #FP/N=FP/(FP+ TN)\n",
    "# print('FPR is: %.4f' % FPR_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Practice with threshold prob = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, try threshold probability = 0.4\n",
    "\n",
    "new_pred = ???\n",
    "\n",
    "cm_new = confusion_matrix(y_test, new_pred)\n",
    "print(\"Confusion matrix:\\n\" , cm_new)\n",
    "\n",
    "# EXERCISE: What is the Accuracy?\n",
    "acc = ???\n",
    "print('Accuracy is: %.4f' %acc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# EXERCISE: What is the True Positive Rate ?\n",
    "TPR_logit = ???\n",
    "print('TPR is: %.4f' % TPR_logit)\n",
    "\n",
    "\n",
    "\n",
    "# EXERCISE: What is the False Positive rate ?\n",
    "FPR_logit = ???\n",
    "print('FPR is: %.4f' % FPR_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take away: After running logistic regression, one can change the threshold probability. This will affect the predicted label. A smaller threshold will result in more observations being predicted as positive. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
